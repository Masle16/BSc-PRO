{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'resources/train'\n",
    "valid_path = 'resources/valid'\n",
    "test_path = 'resources/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 299 images belonging to 3 classes.\n",
      "Found 82 images belonging to 3 classes.\n",
      "Found 35 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(rotation_range = 90, horizontal_flip=True, vertical_flip=True).flow_from_directory(train_path, target_size=(224,224), classes=['potato', 'catfood', 'table'], batch_size = 10)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['potato', 'catfood', 'table'], batch_size = 5)\n",
    "test_batches  = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['potato', 'catfood', 'table'], batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 299 images belonging to 3 classes.\n",
      "Found 82 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        classes=['potato', 'catfood', 'table'])  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        valid_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        classes=['potato', 'catfood', 'table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = mobilenet.MobileNet(weights='imagenet', include_top = False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import plot_model\n",
    "#plot_model(base_model, to_file='model_NoTop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 4,281,539\n",
      "Trainable params: 1,052,675\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "preds=Dense(3,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3, 3, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3, 3, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3, 3, 512)         524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3, 3, 3)           1539      \n",
      "=================================================================\n",
      "Total params: 5,854,403\n",
      "Trainable params: 2,625,539\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "model = models.Sequential()\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(base_model)\n",
    "\n",
    "# Add new layers\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "    \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "# predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 1.5084 - acc: 0.8436 - val_loss: 0.7239 - val_acc: 0.7500\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 3s 139ms/step - loss: 0.1665 - acc: 0.9652 - val_loss: 0.4678 - val_acc: 0.8438\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 3s 147ms/step - loss: 0.4435 - acc: 0.9359 - val_loss: 0.2738 - val_acc: 0.8333\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 0.1551 - acc: 0.9479 - val_loss: 0.4520 - val_acc: 0.8438\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 3s 139ms/step - loss: 0.0899 - acc: 0.9757 - val_loss: 0.3883 - val_acc: 0.8125\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 0.7225 - acc: 0.9305 - val_loss: 0.3436 - val_acc: 0.8333\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 3s 141ms/step - loss: 0.0678 - acc: 0.9896 - val_loss: 0.8551 - val_acc: 0.8125\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 3s 142ms/step - loss: 0.2840 - acc: 0.9374 - val_loss: 0.2777 - val_acc: 0.8438\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 3s 144ms/step - loss: 0.0273 - acc: 0.9861 - val_loss: 0.5467 - val_acc: 0.7778\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 3s 143ms/step - loss: 0.5689 - acc: 0.9330 - val_loss: 0.3303 - val_acc: 0.8125\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 3s 144ms/step - loss: 0.1001 - acc: 0.9826 - val_loss: 0.0431 - val_acc: 0.9688\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 3s 143ms/step - loss: 0.0057 - acc: 0.9965 - val_loss: 0.3150 - val_acc: 0.7778\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 3s 143ms/step - loss: 0.2505 - acc: 0.9498 - val_loss: 0.2553 - val_acc: 0.8125\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 3s 145ms/step - loss: 6.5735e-04 - acc: 1.0000 - val_loss: 0.0796 - val_acc: 0.9375\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 0.0257 - acc: 0.9896 - val_loss: 0.2848 - val_acc: 0.8333\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 0.0258 - acc: 0.9896 - val_loss: 0.2003 - val_acc: 0.9062\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 3s 154ms/step - loss: 0.0217 - acc: 0.9965 - val_loss: 0.0284 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 0.2442 - acc: 0.9473 - val_loss: 0.1272 - val_acc: 0.9444\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 3s 147ms/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.1066 - val_acc: 0.9062\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 3s 154ms/step - loss: 0.0758 - acc: 0.9791 - val_loss: 0.1135 - val_acc: 0.9375\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 3s 154ms/step - loss: 0.0328 - acc: 0.9896 - val_loss: 0.0353 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 3s 153ms/step - loss: 0.0947 - acc: 0.9826 - val_loss: 0.0659 - val_acc: 0.9688\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 3s 141ms/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.1150e-05 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 0.0536 - acc: 0.9896 - val_loss: 0.0934 - val_acc: 0.9688\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 0.3165 - acc: 0.9513 - val_loss: 0.0914 - val_acc: 0.9375\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 3s 146ms/step - loss: 0.0109 - acc: 0.9930 - val_loss: 0.0489 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 3s 153ms/step - loss: 1.5391e-05 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 3s 153ms/step - loss: 9.6739e-07 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9688\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 9.8682e-05 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 0.9444\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 4.8431e-06 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9688\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 10s 542ms/step - loss: 1.9248e-05 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 6s 327ms/step - loss: 3.1843e-05 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9444\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 5s 275ms/step - loss: 3.9080e-06 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.1520 - acc: 0.9861 - val_loss: 0.0506 - val_acc: 0.9688\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 4s 218ms/step - loss: 0.0497 - acc: 0.9826 - val_loss: 7.2460e-05 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 4s 215ms/step - loss: 0.0895 - acc: 0.9791 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 4s 196ms/step - loss: 1.3184e-05 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.5200 - acc: 0.9548 - val_loss: 0.1822 - val_acc: 0.9444\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.0296 - acc: 0.9861 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.0516 - acc: 0.9846 - val_loss: 0.0532 - val_acc: 0.9688\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.0072 - acc: 0.9965 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 2.6399e-06 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 0.0908 - acc: 0.9826 - val_loss: 0.3013 - val_acc: 0.9062\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 3s 158ms/step - loss: 1.6893e-04 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 9.5759e-06 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9375\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 3s 163ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.4701 - val_acc: 0.8125\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 3s 153ms/step - loss: 1.7333e-06 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9444\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 3s 158ms/step - loss: 0.4544 - acc: 0.9652 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 1.9012e-07 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9132d8b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=18, epochs=50, validation_data=validation_generator, validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    ")\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "test_generator = valid_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        classes=['potato', 'catfood', 'table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(test_generator)\n",
    "\n",
    "ynew = model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.07, 0.93],\n",
       "       [0.  , 0.23, 0.77],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.01, 0.99],\n",
       "       [0.  , 0.09, 0.91],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.  , 0.33, 0.67]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(ynew, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "16/16 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05216670036315918, 1.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(imgs,labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "gul_path = 'tfpoet/tf_files/test/gulerod.jpg'\n",
    "img = image.load_img(gul_path, target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = img\n",
    "img = np.expand_dims(img, axis=0)\n",
    "out = model.predict(img)\n",
    "print(np.round(out, decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
